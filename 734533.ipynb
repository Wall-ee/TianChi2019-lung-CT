{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "#安装 simple itk\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install SimpleITK -t /home/aistudio/external-libraries\n",
    "!pip install tqdm -t /home/aistudio/external-libraries\n",
    "!pip install scikit-image==0.17.2 --no-dependencies -t /home/aistudio/external-libraries\n",
    "!pip install tifffile>=2019.7.26 -t /home/aistudio/external-libraries\n",
    "!pip install lxml -t /home/aistudio/external-libraries\n",
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple\n",
    "# networkx>=2.0\n",
    "# pillow>=4.3.0,!=7.1.0,!=7.1.1\n",
    "# imageio>=2.3.0\n",
    "\n",
    "# PyWavelets>=1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\r\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chestCT_round1_annotation.csv', 'chestCT_round1_testA.zip', 'chestCT_round1_train_part1.zip', 'chestCT_round1_train_part2.zip', 'chestCT_round1_train_part3.zip', 'chestCT_round1_train_part4.zip', 'chestCT_round1_train_part5.zip', '']\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_testA.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_testA.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part1.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part1.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part2.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part2.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part3.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part3.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part4.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part4.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part5.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part5.zip successful\n"
     ]
    }
   ],
   "source": [
    "#解押文件操作\n",
    "import os\n",
    "os.chdir('/home/aistudio/data/data8689')\n",
    "import subprocess\n",
    "\n",
    "def excuteCommand(com):\n",
    "    ex = subprocess.Popen(com, stdout=subprocess.PIPE, shell=True)\n",
    "    out, err  = ex.communicate()\n",
    "    status = ex.wait()\n",
    "    print(\"cmd in:\", com)\n",
    "    print(\"cmd out: \", out.decode())\n",
    "    return out.decode()\n",
    "dataFileNameList = os.popen('ls').read().split('\\n')\n",
    "print (dataFileNameList)\n",
    "for dataFile in dataFileNameList:\n",
    "    if '.zip' in dataFile:\n",
    "        print('unziping file...')\n",
    "        unzipResult = excuteCommand('unzip ' + str(dataFile)+ ' > /dev/null')\n",
    "        # print(unzipResult)\n",
    "        try:\n",
    "            os.remove(str(dataFile))\n",
    "            print('deleting {} successful'.format(dataFile))\n",
    "        except Exception as e:\n",
    "            print('deleting {} with error {}'.format(dataFile,str(e)))\n",
    "# print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part1/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part2/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part4/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part5/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part3/* train/\n",
      "cmd out:  \n"
     ]
    }
   ],
   "source": [
    "#将所有train_part文件夹 放到 train目录里面\n",
    "#目标文件夹，此处为相对路径，也可以改为绝对路径\n",
    "os.chdir('/home/aistudio/work')\n",
    "determination = 'train/'\n",
    "if not os.path.exists(determination):\n",
    "    os.makedirs(determination)\n",
    "\n",
    "#源文件夹路径\n",
    "dataPath = r'/home/aistudio/data/data8689'\n",
    "folders= os.listdir(dataPath)\n",
    "for folder in folders:\n",
    "    if 'train_part' in folder:\n",
    "        # dir = path + '/' +  str(folder)\n",
    "        copyFileResult = excuteCommand('\\cp -rf --link {}/* {}/'.format((dataPath+ '/' +  str(folder)),'train'))\n",
    "        \n",
    "        # files = os.listdir(dir)\n",
    "        # for fileName in files:\n",
    "        #     source = dir + '\\\\' + str(file)\n",
    "        #     deter = determination + str(file)\n",
    "        #     shutil.copyfile(source, deter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ct世界坐标转换\n",
    "# import sys\n",
    "# sys.path.append('/home/aistudio/external-libraries')\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import SimpleITK as sitk\n",
    "\n",
    "# pd.set_option('display.width', 120)\n",
    "\n",
    "# annotation_file = '/home/aistudio/data/data8689/chestCT_round1_annotation.csv'\n",
    "# df = pd.read_csv(annotation_file, dtype={'seriesuid': int, 'label': int})\n",
    "# # print(df.head())\n",
    "# #遍历并转换坐标\n",
    "# for uid in df['seriesuid'].unique():\n",
    "#     idx = df['seriesuid'] == uid\n",
    "#     mhd_file = './train/{}.mhd'.format(uid)\n",
    "#     itk_image = sitk.ReadImage(mhd_file)\n",
    "#     origin = np.array(itk_image.GetOrigin())\n",
    "#     spacing = np.array(itk_image.GetSpacing())\n",
    "#     df.loc[idx, ['coordX', 'coordY', 'coordZ']] = ((df.loc[idx, ['coordX', 'coordY', 'coordZ']] - origin) / spacing).round()\n",
    "#     df.loc[idx, ['diameterX', 'diameterY', 'diameterZ']] = (df.loc[idx, ['diameterX', 'diameterY', 'diameterZ']] / spacing).round()\n",
    "\n",
    "# df = df.astype('int64')\n",
    "# print(df.head(10))\n",
    "# df.to_csv('./annotation_voxel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成标记图片\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import lt_annotation\n",
    "os.chdir('/home/aistudio/work')\n",
    "\n",
    "sets = ['./train']\n",
    "data_path = '/home/aistudio/work'\n",
    "png_image_path = './image_png'\n",
    "anns_path = '/home/aistudio/data/data8689/chestCT_round1_annotation.csv'\n",
    "\n",
    "lt_annotation.DoMain(sets,data_path,png_image_path,anns_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成全部png 图片 先生成标记 然后反向生成图片 省地方\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import generate_the_image\n",
    "os.chdir('/home/aistudio/work')\n",
    "file_paths = ['./train']\n",
    "save_path = './image_png'\n",
    "markedFileName = 'train.txt'\n",
    "for file_path in file_paths:\n",
    "    files = generate_the_image.get_file_name(file_path)\n",
    "    images = generate_the_image.get_all_image(file_path, files, save_path, save_image=True,trainFileName=markedFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#标注名字\n",
    "label_mapper = {\n",
    "    1: 'nodule',\n",
    "    5: 'stripe',\n",
    "    31: 'artery',\n",
    "    32: 'lymph',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 17167/17167 [00:43<00:00, 397.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#转换yolo 及 voc 格式 参考 https://blog.csdn.net/qq_29762941/article/details/80797790\n",
    "#生成VOCxml文件\n",
    "os.chdir('/home/aistudio/work')\n",
    "determination = 'Annotations/'\n",
    "if not os.path.exists(determination):\n",
    "    os.makedirs(determination)\n",
    "!cd /home/aistudio/work\n",
    "!python yolotovoc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#图像增强\n",
    "from paddlex.det import transforms\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.Normalize(),\n",
    "#     transforms.ResizeByShort(short_size=800, max_size=1333),\n",
    "#     transforms.Padding(coarsest_stride=32)\n",
    "# ])\n",
    "\n",
    "# eval_transforms = transforms.Compose([\n",
    "#     transforms.Normalize(),\n",
    "#     transforms.ResizeByShort(short_size=800, max_size=1333),\n",
    "#     transforms.Padding(coarsest_stride=32),\n",
    "# ])\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 23:03:29 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-17 23:03:46 [INFO]\t17167 samples in file ./train_list_voc.txt\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#载入VOC数据及 训练数据集\n",
    "os.chdir('/home/aistudio/work')\n",
    "train_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='/home/aistudio/work/',\n",
    "    file_list='./train_list_voc.txt',\n",
    "    label_list='./labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "# eval_dataset = pdx.datasets.VOCDetection(\n",
    "#     data_dir='insect_det',\n",
    "#     file_list='insect_det/val_list.txt',\n",
    "#     label_list='insect_det/labels.txt',\n",
    "#     transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 如果要通过VisualDL查看日志页面，下没按这行代码需要执行\n",
    "# aistudio上需要将日志输出到/home/aistudio/log目录下才可以查看VisuaDL界面\n",
    "! rm -rf ~/log & rm -rf output/faster_rcnn_r50_fpn\n",
    "! mkdir -p output/faster_rcnn_r50_fpn/vdl_log\n",
    "! ln -s output/faster_rcnn_r50_fpn/vdl_log ~/log\n",
    "\n",
    "num_classes = len(train_dataset.labels) + 1\n",
    "model = pdx.det.FasterRCNN(num_classes=num_classes)\n",
    "model.train(\n",
    "    num_epochs=12,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=2,\n",
    "    # eval_dataset=eval_dataset, \n",
    "    learning_rate=0.0025,\n",
    "    lr_decay_epochs=[8, 11],\n",
    "    save_interval_epochs=1,\n",
    "    save_dir='output/faster_rcnn_r50_fpn',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:47 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:48,181-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-08-18 23:31:48,718-INFO: generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:48 [INFO]\tThe visualized result is saved as ./output/faster_rcnn_r50_fpn_predict/visualize_318818_000.png\n"
     ]
    }
   ],
   "source": [
    "#加载模型部署\n",
    "# import paddlex as pdx\n",
    "# import os\n",
    "# os.chdir('/home/aistudio/work')\n",
    "# # test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "# model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "# image_name = './image_png/318818_000.png'\n",
    "# #如未在训练时定义eval_dataset，那在调用预测predict接口时，用户需要再重新定义test_transforms传入给predict接口\n",
    "# result = model.predict(image_name,transforms=eval_transforms)\n",
    "# pdx.det.visualize(image_name, result, threshold=0.5,save_dir='./output/faster_rcnn_r50_fpn_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:29<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#生成测试用png 图片\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import generate_the_image\n",
    "os.chdir('/home/aistudio/work')\n",
    "file_paths = ['/home/aistudio/data/data8689/testA']\n",
    "save_path = './test_image_png'\n",
    "for file_path in file_paths:\n",
    "    files = generate_the_image.get_file_name(file_path)\n",
    "    # print(files)\n",
    "    images = generate_the_image.get_all_image(file_path, files, save_path, save_image=True)\n",
    "\n",
    "#对真实测试数据fcrnn预测\n",
    "# testFileNameList = os.listdir('/home/aistudio/data/data8689/testA')\n",
    "# testFileNameList = list(map(lambda x:'../data/data8689/testA/'+str(x),testFileNameList))\n",
    "#生成png图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-19 22:58:08 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17167/17167 [36:04<00:00,  7.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#对训练数据进行批量预测 使用png 图片预测\n",
    "import pandas as pd\n",
    "import paddlex as pdx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/aistudio/work')\n",
    "# test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "# image_name = './image_png/318818_000.png'\n",
    "\n",
    "\n",
    "#对训练数据fcrnn预测\n",
    "trainListVocDF = pd.read_csv('train_list_voc.txt',names=[0,1],sep=' ')\n",
    "trainFileNameList = list('./' + trainListVocDF[0])\n",
    "trainPredictResultList= []\n",
    "for trainFile in tqdm(trainFileNameList):\n",
    "    # print(trainFile)\n",
    "    tempPredict = model.predict(trainFile,transforms=eval_transforms)\n",
    "    trainPredictResultList.append({'pic_name':trainFile,'predict_result':tempPredict})\n",
    "    # print(tempPredict)\n",
    "# trainPredictResultList = model.batch_predict(trainFileNameList, transforms=eval_transforms, thread_num=4)\n",
    "trainPredictResultDF = pd.DataFrame(trainPredictResultList)\n",
    "trainPredictResultDF.to_csv('./train_predict_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对测试数据进行预测  使用png 图片预测\n",
    "import pandas as pd\n",
    "import paddlex as pdx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/aistudio/work')\n",
    "# test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "\n",
    "#读取测试数据图片名称列表\n",
    "testFileNameList = os.listdir('./test_image_png')\n",
    "testFileNameList = list(map(lambda x:'./test_image_png/'+str(x),testFileNameList))\n",
    "\n",
    "#对测试数据fcrnn预测\n",
    "testFCRNNPredictResultList= []\n",
    "for testFile in tqdm(testFileNameList):\n",
    "    # print(trainFile)\n",
    "    tempPredict = model.predict(testFile,transforms=eval_transforms)\n",
    "    testFCRNNPredictResultList.append({'pic_name':testFile,'predict_result':tempPredict})\n",
    "    # print(tempPredict)\n",
    "# trainPredictResultList = model.batch_predict(trainFileNameList, transforms=eval_transforms, thread_num=4)\n",
    "testFCRNNPredictResultDF = pd.DataFrame(testFCRNNPredictResultList)\n",
    "testFCRNNPredictResultDF.to_csv('./test_fcrnn_predict_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-24 01:14:12 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:14<23:48,  4.81s/it]"
     ]
    }
   ],
   "source": [
    "#对训练及测试数据进行预测 采用ct原始数据进行预测\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "\n",
    "from work.LungCT2019 import predict_train_frcnn\n",
    "predict_train_frcnn.detect_img_lt_like_annotation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aistudio/data/data8689/train_part1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c1cf39424768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLungCT2019\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_image_and_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mget_image_and_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoGenerateResNetImageAndLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/LungCT2019/get_image_and_label.py\u001b[0m in \u001b[0;36mDoGenerateResNetImageAndLabel\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m                                     \u001b[0mimage_class_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./image_class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                                     \u001b[0mimage_type_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                                     \u001b[0moutput_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_list.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                                     )\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m#生成测试数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LungCT2019/get_image_and_label.py\u001b[0m in \u001b[0;36mget_image_and_label\u001b[0;34m(sets, data_path, anns_path, predict_path, target_size, image_class_save_path, image_type_path, output_file_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mpredict_anns_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mfrom_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mfile_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcurrent_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mhd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/LungCT2019/get_image_and_label.py\u001b[0m in \u001b[0;36mget_file_id\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mf_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mhd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mhd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aistudio/data/data8689/train_part1'"
     ]
    }
   ],
   "source": [
    "#对训练及测试数据进行预测 采用ct原始数据进行预测\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "\n",
    "from work.LungCT2019 import get_image_and_label\n",
    "get_image_and_label.DoGenerateResNetImageAndLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成训练集实例分类列表\n",
    "# os.chdir('./image_class/train')\n",
    "# wrongFileList= os.listdir('./0')\n",
    "# wrongFileList = list(map(lambda x:'0/'+x+ ' 0',wrongFileList))\n",
    "# f = open('train_list.txt','w')\n",
    "# f.write('\\n'.join(wrongFileList))\n",
    "# f.write('\\n')\n",
    "# rightFileList = os.listdir('./1')\n",
    "# rightFileList = list(map(lambda x:'1/'+x+ ' 1',rightFileList))\n",
    "# f.write('\\n'.join(rightFileList))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成测试集实例分类列表\n",
    "# os.chdir('../../image_class/val')\n",
    "# wrongFileList= os.listdir('./0')\n",
    "# wrongFileList = list(map(lambda x:'0/'+x+ ' 0',wrongFileList))\n",
    "# f = open('val_list.txt','w')\n",
    "# f.write('\\n'.join(wrongFileList))\n",
    "# f.write('\\n')\n",
    "# rightFileList = os.listdir('./1')\n",
    "# rightFileList = list(map(lambda x:'1/'+x+ ' 1',rightFileList))\n",
    "# f.write('\\n'.join(rightFileList))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-25 22:04:43 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-25 22:04:50 [INFO]\t737585 samples in file /home/aistudio/work/image_class/train/train_list.txt\n",
      "2020-08-25 22:04:50 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-25 22:04:51 [INFO]\t183023 samples in file /home/aistudio/work/image_class/val/val_list.txt\n"
     ]
    }
   ],
   "source": [
    "#训练resnet\n",
    "#直接执行也行 !python ResNet_train.py\n",
    "import numpy as np\n",
    "import os\n",
    "# from get_image_and_label import get_image_and_label\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "os.chdir('/home/aistudio/work')\n",
    "\n",
    "#图像增强\n",
    "from paddlex.det import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "train_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/work/image_class/train',\n",
    "    file_list='/home/aistudio/work/image_class/train/train_list.txt',\n",
    "    label_list='/home/aistudio/work/image_class/train//labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/work/image_class/val',\n",
    "    file_list='/home/aistudio/work/image_class/val/val_list.txt',\n",
    "    label_list='/home/aistudio/work/image_class/val/labels.txt',\n",
    "    transforms=eval_transforms)\n",
    "\n",
    "# 如果要通过VisualDL查看日志页面，下没按这行代码需要执行\n",
    "# aistudio上需要将日志输出到/home/aistudio/log目录下才可以查看VisuaDL界面\n",
    "# ! rm -rf ~/log & rm -rf resnet_output/resnet_50\n",
    "# ! mkdir -p resnet_output/resnet_50/vdl_log\n",
    "# ! ln -s resnet_output/resnet_50/vdl_log ~/log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173939/173939 [00:12<00:00, 14326.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# print(train_dataset.labels)\n",
    "#将图片变为ndarray  float32\n",
    "os.chdir('/home/aistudio/work/image_class/val')\n",
    "fileList = os.listdir('./0')\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "for filename in tqdm(fileList):\n",
    "    image = cv2.imread(filename)\n",
    "    image = np.asarray(image).astype(np.float32)\n",
    "    cv2.imwrite(filename, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-25 22:05:26 [INFO]\tConnecting PaddleHub server to get pretrain weights...\n",
      "2020-08-25 22:05:29 [INFO]\tLoad pretrain weights from resnet_output/resnet_50/pretrain/ResNet50.\n",
      "2020-08-25 22:05:29 [WARNING]\t[SKIP] Shape of pretrained weight resnet_output/resnet_50/pretrain/ResNet50/fc_0.w_0 doesn't match.(Pretrained: (2048, 1000), Actual: (2048, 3))\n",
      "2020-08-25 22:05:29 [WARNING]\t[SKIP] Shape of pretrained weight resnet_output/resnet_50/pretrain/ResNet50/fc_0.b_0 doesn't match.(Pretrained: (1000,), Actual: (3,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-25 22:05:29,743-WARNING: resnet_output/resnet_50/pretrain/ResNet50.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-25 22:05:30 [INFO]\tThere are 265 varaibles in resnet_output/resnet_50/pretrain/ResNet50 are loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Process Process-2:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Process Process-3:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "TypeError: 'int' object does not support item assignment\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Process Process-4:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "TypeError: 'int' object does not support item assignment\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-5:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "2020-08-25 22:05:42,226-WARNING: Your reader has raised an exception!\n",
      "TypeError: 'int' object does not support item assignment\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-6:\n",
      "TypeError: 'int' object does not support item assignment\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1156, in __thread_main__\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1136, in __thread_main__\n",
      "    for tensors in self._tensor_reader():\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\", line 1206, in __tensor_reader_impl__\n",
      "    for slots in paddle_reader():\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py\", line 505, in __reader_creator__\n",
      "    for item in reader():\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 187, in queue_reader\n",
      "    raise ValueError(\"multiprocess reader raises an exception\")\n",
      "ValueError: multiprocess reader raises an exception\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: 'int' object does not support item assignment\n",
      "Process Process-7:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "TypeError: 'int' object does not support item assignment\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "Process Process-8:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n"
     ]
    },
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\n\n----------------------\nError Message Summary:\n----------------------\nError: Blocking queue is killed because the data reader raises an exception\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fdf9e8accefb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msave_interval_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet_output/resnet_50'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     use_vdl=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, save_interval_epochs, log_interval_steps, save_dir, pretrain_weights, optimizer, learning_rate, warmup_steps, warmup_start_lr, lr_decay_epochs, lr_decay_gamma, use_vdl, sensitivities_file, eval_metric_loss, early_stop, early_stop_patience, resume_checkpoint)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0muse_vdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_vdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             early_stop_patience=early_stop_patience)\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/base.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, save_interval_epochs, log_interval_steps, save_dir, use_vdl, early_stop, early_stop_patience)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mstep_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 outputs = self.exe.run(\n\u001b[1;32m    483\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_train_prog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/reader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_next_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::operators::reader::BlockingQueue<std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> > >::Receive(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\n3   paddle::operators::reader::PyReader::ReadNext(std::vector<paddle::framework::LoDTensor, std::allocator<paddle::framework::LoDTensor> >*)\n4   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<unsigned long>, std::__future_base::_Result_base::_Deleter>, unsigned long> >::_M_invoke(std::_Any_data const&)\n5   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n6   ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const\n\n----------------------\nError Message Summary:\n----------------------\nError: Blocking queue is killed because the data reader raises an exception\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] at (/paddle/paddle/fluid/operators/reader/blocking_queue.h:141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypeError: 'int' object does not support item assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 166, in _read_into_queue\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/datasets/dataset.py\", line 156, in _read_into_queue\n",
      "    result = mapper(sample[0], sample[1])\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 136, in __call__\n",
      "    outputs = decode_image(im, im_info, label_info)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/det_transforms.py\", line 119, in decode_image\n",
      "    [im.shape[0], im.shape[1], 1.], dtype=np.float32)\n",
      "TypeError: 'int' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.labels) + 1\n",
    "# print(train_dataset.labels)\n",
    "model1 = pdx.cls.ResNet50_vd_ssld(num_classes=num_classes)\n",
    "model1.train(\n",
    "    num_epochs=200,\n",
    "    train_dataset=train_dataset,\n",
    "    # train_batch_size=32,\n",
    "    eval_dataset=eval_dataset, \n",
    "    # learning_rate=0.5e-6,\n",
    "    # lr_decay_epochs=[8, 11],\n",
    "    save_interval_epochs=10,\n",
    "    save_dir='resnet_output/resnet_50',\n",
    "    use_vdl=True)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(eval_dataset, verbose=1)\n",
    "for key in scores.keys():\n",
    "    print('Val Result is {} : {}'.format(str(key),str(scores[key])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
