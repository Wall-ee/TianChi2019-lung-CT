{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "#安装 simple itk\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install SimpleITK -t /home/aistudio/external-libraries\n",
    "!pip install tqdm -t /home/aistudio/external-libraries\n",
    "!pip install scikit-image==0.17.2 --no-dependencies -t /home/aistudio/external-libraries\n",
    "!pip install tifffile>=2019.7.26 -t /home/aistudio/external-libraries\n",
    "!pip install lxml -t /home/aistudio/external-libraries\n",
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple\n",
    "# networkx>=2.0\n",
    "# pillow>=4.3.0,!=7.1.0,!=7.1.1\n",
    "# imageio>=2.3.0\n",
    "\n",
    "# PyWavelets>=1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\r\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chestCT_round1_annotation.csv', 'chestCT_round1_testA.zip', 'chestCT_round1_train_part1.zip', 'chestCT_round1_train_part2.zip', 'chestCT_round1_train_part3.zip', 'chestCT_round1_train_part4.zip', 'chestCT_round1_train_part5.zip', '']\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_testA.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_testA.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part1.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part1.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part2.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part2.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part3.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part3.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part4.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part4.zip successful\n",
      "unziping file...\n",
      "cmd in: unzip chestCT_round1_train_part5.zip > /dev/null\n",
      "cmd out:  \n",
      "deleting chestCT_round1_train_part5.zip successful\n"
     ]
    }
   ],
   "source": [
    "#解押文件操作\n",
    "import os\n",
    "os.chdir('/home/aistudio/data/data8689')\n",
    "import subprocess\n",
    "\n",
    "def excuteCommand(com):\n",
    "    ex = subprocess.Popen(com, stdout=subprocess.PIPE, shell=True)\n",
    "    out, err  = ex.communicate()\n",
    "    status = ex.wait()\n",
    "    print(\"cmd in:\", com)\n",
    "    print(\"cmd out: \", out.decode())\n",
    "    return out.decode()\n",
    "dataFileNameList = os.popen('ls').read().split('\\n')\n",
    "print (dataFileNameList)\n",
    "for dataFile in dataFileNameList:\n",
    "    if '.zip' in dataFile:\n",
    "        print('unziping file...')\n",
    "        unzipResult = excuteCommand('unzip ' + str(dataFile)+ ' > /dev/null')\n",
    "        # print(unzipResult)\n",
    "        try:\n",
    "            os.remove(str(dataFile))\n",
    "            print('deleting {} successful'.format(dataFile))\n",
    "        except Exception as e:\n",
    "            print('deleting {} with error {}'.format(dataFile,str(e)))\n",
    "# print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part1/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part2/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part4/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part5/* train/\n",
      "cmd out:  \n",
      "cmd in: \\cp -rf --link /home/aistudio/data/data8689/train_part3/* train/\n",
      "cmd out:  \n"
     ]
    }
   ],
   "source": [
    "#将所有train_part文件夹 放到 train目录里面\n",
    "#目标文件夹，此处为相对路径，也可以改为绝对路径\n",
    "os.chdir('/home/aistudio/work')\n",
    "determination = 'train/'\n",
    "if not os.path.exists(determination):\n",
    "    os.makedirs(determination)\n",
    "\n",
    "#源文件夹路径\n",
    "dataPath = r'/home/aistudio/data/data8689'\n",
    "folders= os.listdir(dataPath)\n",
    "for folder in folders:\n",
    "    if 'train_part' in folder:\n",
    "        # dir = path + '/' +  str(folder)\n",
    "        copyFileResult = excuteCommand('\\cp -rf --link {}/* {}/'.format((dataPath+ '/' +  str(folder)),'train'))\n",
    "        \n",
    "        # files = os.listdir(dir)\n",
    "        # for fileName in files:\n",
    "        #     source = dir + '\\\\' + str(file)\n",
    "        #     deter = determination + str(file)\n",
    "        #     shutil.copyfile(source, deter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ct世界坐标转换\n",
    "# import sys\n",
    "# sys.path.append('/home/aistudio/external-libraries')\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import SimpleITK as sitk\n",
    "\n",
    "# pd.set_option('display.width', 120)\n",
    "\n",
    "# annotation_file = '/home/aistudio/data/data8689/chestCT_round1_annotation.csv'\n",
    "# df = pd.read_csv(annotation_file, dtype={'seriesuid': int, 'label': int})\n",
    "# # print(df.head())\n",
    "# #遍历并转换坐标\n",
    "# for uid in df['seriesuid'].unique():\n",
    "#     idx = df['seriesuid'] == uid\n",
    "#     mhd_file = './train/{}.mhd'.format(uid)\n",
    "#     itk_image = sitk.ReadImage(mhd_file)\n",
    "#     origin = np.array(itk_image.GetOrigin())\n",
    "#     spacing = np.array(itk_image.GetSpacing())\n",
    "#     df.loc[idx, ['coordX', 'coordY', 'coordZ']] = ((df.loc[idx, ['coordX', 'coordY', 'coordZ']] - origin) / spacing).round()\n",
    "#     df.loc[idx, ['diameterX', 'diameterY', 'diameterZ']] = (df.loc[idx, ['diameterX', 'diameterY', 'diameterZ']] / spacing).round()\n",
    "\n",
    "# df = df.astype('int64')\n",
    "# print(df.head(10))\n",
    "# df.to_csv('./annotation_voxel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成标记图片\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import lt_annotation\n",
    "os.chdir('/home/aistudio/work')\n",
    "\n",
    "sets = ['./train']\n",
    "data_path = '/home/aistudio/work'\n",
    "png_image_path = './image_png'\n",
    "anns_path = '/home/aistudio/data/data8689/chestCT_round1_annotation.csv'\n",
    "\n",
    "lt_annotation.DoMain(sets,data_path,png_image_path,anns_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成全部png 图片 先生成标记 然后反向生成图片 省地方\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import generate_the_image\n",
    "os.chdir('/home/aistudio/work')\n",
    "file_paths = ['./train']\n",
    "save_path = './image_png'\n",
    "markedFileName = 'train.txt'\n",
    "for file_path in file_paths:\n",
    "    files = generate_the_image.get_file_name(file_path)\n",
    "    images = generate_the_image.get_all_image(file_path, files, save_path, save_image=True,trainFileName=markedFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#标注名字\n",
    "label_mapper = {\n",
    "    1: 'nodule',\n",
    "    5: 'stripe',\n",
    "    31: 'artery',\n",
    "    32: 'lymph',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 17167/17167 [00:43<00:00, 397.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#转换yolo 及 voc 格式 参考 https://blog.csdn.net/qq_29762941/article/details/80797790\n",
    "#生成VOCxml文件\n",
    "os.chdir('/home/aistudio/work')\n",
    "determination = 'Annotations/'\n",
    "if not os.path.exists(determination):\n",
    "    os.makedirs(determination)\n",
    "!cd /home/aistudio/work\n",
    "!python yolotovoc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#图像增强\n",
    "from paddlex.det import transforms\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.Normalize(),\n",
    "#     transforms.ResizeByShort(short_size=800, max_size=1333),\n",
    "#     transforms.Padding(coarsest_stride=32)\n",
    "# ])\n",
    "\n",
    "# eval_transforms = transforms.Compose([\n",
    "#     transforms.Normalize(),\n",
    "#     transforms.ResizeByShort(short_size=800, max_size=1333),\n",
    "#     transforms.Padding(coarsest_stride=32),\n",
    "# ])\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-17 23:03:29 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-17 23:03:46 [INFO]\t17167 samples in file ./train_list_voc.txt\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#载入VOC数据及 训练数据集\n",
    "os.chdir('/home/aistudio/work')\n",
    "train_dataset = pdx.datasets.VOCDetection(\n",
    "    data_dir='/home/aistudio/work/',\n",
    "    file_list='./train_list_voc.txt',\n",
    "    label_list='./labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "# eval_dataset = pdx.datasets.VOCDetection(\n",
    "#     data_dir='insect_det',\n",
    "#     file_list='insect_det/val_list.txt',\n",
    "#     label_list='insect_det/labels.txt',\n",
    "#     transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 如果要通过VisualDL查看日志页面，下没按这行代码需要执行\n",
    "# aistudio上需要将日志输出到/home/aistudio/log目录下才可以查看VisuaDL界面\n",
    "! rm -rf ~/log & rm -rf output/faster_rcnn_r50_fpn\n",
    "! mkdir -p output/faster_rcnn_r50_fpn/vdl_log\n",
    "! ln -s output/faster_rcnn_r50_fpn/vdl_log ~/log\n",
    "\n",
    "num_classes = len(train_dataset.labels) + 1\n",
    "model = pdx.det.FasterRCNN(num_classes=num_classes)\n",
    "model.train(\n",
    "    num_epochs=12,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=2,\n",
    "    # eval_dataset=eval_dataset, \n",
    "    learning_rate=0.0025,\n",
    "    lr_decay_epochs=[8, 11],\n",
    "    save_interval_epochs=1,\n",
    "    save_dir='output/faster_rcnn_r50_fpn',\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:47 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:48,181-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-08-18 23:31:48,718-INFO: generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-18 23:31:48 [INFO]\tThe visualized result is saved as ./output/faster_rcnn_r50_fpn_predict/visualize_318818_000.png\n"
     ]
    }
   ],
   "source": [
    "#加载模型部署\n",
    "# import paddlex as pdx\n",
    "# import os\n",
    "# os.chdir('/home/aistudio/work')\n",
    "# # test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "# model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "# image_name = './image_png/318818_000.png'\n",
    "# #如未在训练时定义eval_dataset，那在调用预测predict接口时，用户需要再重新定义test_transforms传入给predict接口\n",
    "# result = model.predict(image_name,transforms=eval_transforms)\n",
    "# pdx.det.visualize(image_name, result, threshold=0.5,save_dir='./output/faster_rcnn_r50_fpn_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:29<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#生成测试用png 图片\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "import SimpleITK as sitk\n",
    "from work.LungCT2019 import generate_the_image\n",
    "os.chdir('/home/aistudio/work')\n",
    "file_paths = ['/home/aistudio/data/data8689/testA']\n",
    "save_path = './test_image_png'\n",
    "for file_path in file_paths:\n",
    "    files = generate_the_image.get_file_name(file_path)\n",
    "    # print(files)\n",
    "    images = generate_the_image.get_all_image(file_path, files, save_path, save_image=True)\n",
    "\n",
    "#对真实测试数据fcrnn预测\n",
    "# testFileNameList = os.listdir('/home/aistudio/data/data8689/testA')\n",
    "# testFileNameList = list(map(lambda x:'../data/data8689/testA/'+str(x),testFileNameList))\n",
    "#生成png图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-19 22:58:08 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17167/17167 [36:04<00:00,  7.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#对训练数据进行批量预测 使用png 图片预测\n",
    "import pandas as pd\n",
    "import paddlex as pdx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/aistudio/work')\n",
    "# test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "# image_name = './image_png/318818_000.png'\n",
    "\n",
    "\n",
    "#对训练数据fcrnn预测\n",
    "trainListVocDF = pd.read_csv('train_list_voc.txt',names=[0,1],sep=' ')\n",
    "trainFileNameList = list('./' + trainListVocDF[0])\n",
    "trainPredictResultList= []\n",
    "for trainFile in tqdm(trainFileNameList):\n",
    "    # print(trainFile)\n",
    "    tempPredict = model.predict(trainFile,transforms=eval_transforms)\n",
    "    trainPredictResultList.append({'pic_name':trainFile,'predict_result':tempPredict})\n",
    "    # print(tempPredict)\n",
    "# trainPredictResultList = model.batch_predict(trainFileNameList, transforms=eval_transforms, thread_num=4)\n",
    "trainPredictResultDF = pd.DataFrame(trainPredictResultList)\n",
    "trainPredictResultDF.to_csv('./train_predict_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对测试数据进行预测  使用png 图片预测\n",
    "import pandas as pd\n",
    "import paddlex as pdx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/aistudio/work')\n",
    "# test_jpg = 'mask_r50_fpn_coco/test.jpg'\n",
    "model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "\n",
    "#读取测试数据图片名称列表\n",
    "testFileNameList = os.listdir('./test_image_png')\n",
    "testFileNameList = list(map(lambda x:'./test_image_png/'+str(x),testFileNameList))\n",
    "\n",
    "#对测试数据fcrnn预测\n",
    "testFCRNNPredictResultList= []\n",
    "for testFile in tqdm(testFileNameList):\n",
    "    # print(trainFile)\n",
    "    tempPredict = model.predict(testFile,transforms=eval_transforms)\n",
    "    testFCRNNPredictResultList.append({'pic_name':testFile,'predict_result':tempPredict})\n",
    "    # print(tempPredict)\n",
    "# trainPredictResultList = model.batch_predict(trainFileNameList, transforms=eval_transforms, thread_num=4)\n",
    "testFCRNNPredictResultDF = pd.DataFrame(testFCRNNPredictResultList)\n",
    "testFCRNNPredictResultDF.to_csv('./test_fcrnn_predict_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-24 01:14:12 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:14<23:48,  4.81s/it]"
     ]
    }
   ],
   "source": [
    "#对训练及测试数据进行预测 采用ct原始数据进行预测\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "\n",
    "from work.LungCT2019 import predict_train_frcnn\n",
    "predict_train_frcnn.detect_img_lt_like_annotation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:41<00:00,  1.35it/s]\n",
      "100%|██████████| 300/300 [04:01<00:00,  1.24it/s]\n",
      "100%|██████████| 300/300 [03:41<00:00,  1.36it/s]\n",
      "100%|██████████| 300/300 [04:05<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#对原始图片提取预测部分的图片以及标注部分的图片 以便于进行resnet 的分类识别和训练\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "\n",
    "from work.LungCT2019 import get_image_and_label\n",
    "get_image_and_label.DoGenerateResNetImageAndLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成训练集实例分类列表\n",
    "# os.chdir('/home/aistudio/work/image_class/train')\n",
    "# wrongFileList= os.listdir('./no')\n",
    "# wrongFileList = list(map(lambda x:'no/'+x+ ' 0',wrongFileList))\n",
    "# f = open('train_list.txt','w')\n",
    "# f.write('\\n'.join(wrongFileList))\n",
    "# f.write('\\n')\n",
    "# rightFileList = os.listdir('./yes')\n",
    "# rightFileList = list(map(lambda x:'yes/'+x+ ' 1',rightFileList))\n",
    "# f.write('\\n'.join(rightFileList))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#生成测试集实例分类列表\n",
    "# os.chdir('../../image_class/val')\n",
    "# wrongFileList= os.listdir('./no')\n",
    "# wrongFileList = list(map(lambda x:'no/'+x+ ' 0',wrongFileList))\n",
    "# f = open('val_list.txt','w')\n",
    "# f.write('\\n'.join(wrongFileList))\n",
    "# f.write('\\n')\n",
    "# rightFileList = os.listdir('./yes')\n",
    "# rightFileList = list(map(lambda x:'yes/'+x+ ' 1',rightFileList))\n",
    "# f.write('\\n'.join(rightFileList))\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 12:13:12 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-26 12:13:19 [INFO]\t737585 samples in file /home/aistudio/work/image_class/train/train_list.txt\n",
      "2020-08-26 12:13:19 [INFO]\tStarting to read file list from dataset...\n",
      "2020-08-26 12:13:20 [INFO]\t183023 samples in file /home/aistudio/work/image_class/val/val_list.txt\n"
     ]
    }
   ],
   "source": [
    "#训练resnet\n",
    "#直接执行也行 !python ResNet_train.py\n",
    "import numpy as np\n",
    "import os\n",
    "# from get_image_and_label import get_image_and_label\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import paddlex as pdx\n",
    "os.chdir('/home/aistudio/work')\n",
    "\n",
    "#图像增强\n",
    "from paddlex.cls import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.CenterCrop(crop_size=64), \n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    # transforms.CenterCrop(crop_size=64), \n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "train_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/work/image_class/train',\n",
    "    file_list='/home/aistudio/work/image_class/train/train_list.txt',\n",
    "    label_list='/home/aistudio/work/image_class/train/labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/work/image_class/val',\n",
    "    file_list='/home/aistudio/work/image_class/val/val_list.txt',\n",
    "    label_list='/home/aistudio/work/image_class/val/labels.txt',\n",
    "    transforms=eval_transforms)\n",
    "\n",
    "# 如果要通过VisualDL查看日志页面，下没按这行代码需要执行\n",
    "# aistudio上需要将日志输出到/home/aistudio/log目录下才可以查看VisuaDL界面\n",
    "# ! rm -rf ~/log & rm -rf resnet_output/resnet_50\n",
    "# ! mkdir -p resnet_output/resnet_50/vdl_log\n",
    "# ! ln -s resnet_output/resnet_50/vdl_log ~/log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173939/173939 [00:12<00:00, 14326.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# print(train_dataset.labels)\n",
    "#将图片变为ndarray  float32\n",
    "# os.chdir('/home/aistudio/work/image_class/val')\n",
    "# fileList = os.listdir('./0')\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# for filename in tqdm(fileList):\n",
    "#     image = cv2.imread(filename)\n",
    "#     image = np.asarray(image).astype(np.float32)\n",
    "#     cv2.imwrite(filename, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_classes = len(train_dataset.labels) + 1\n",
    "# print(train_dataset.labels)\n",
    "model = pdx.cls.ResNet50(num_classes=2)\n",
    "model.train(\n",
    "    num_epochs=50,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=128,\n",
    "    eval_dataset=eval_dataset, \n",
    "    learning_rate=0.5e-6,\n",
    "    # lr_decay_epochs=[8, 11],\n",
    "    save_interval_epochs=10,\n",
    "    save_dir='resnet_output/resnet_50',\n",
    "    use_vdl=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 21:38:25 [INFO]\tStart to evaluating(total_samples=183023, total_steps=183023)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183023/183023 [24:29<00:00, 124.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score is  OrderedDict([('acc1', 0.9503067920425302), ('acc2', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(eval_dataset)\n",
    "print('model score is ',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category_id': 0, 'category': 'no', 'score': 0.95524794}]\n"
     ]
    }
   ],
   "source": [
    "test_image = './image_class/val/yes/688588_273.png'\n",
    "aaaaa = model.predict(test_image,transforms=eval_transforms)\n",
    "print(aaaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/aistudio/work')\n",
    "from work.LungCT2019 import ResNet_test\n",
    "ResNet_test.DoResnetPredict()\n",
    "\n",
    "# dataframe = pd.DataFrame({'seriesuid': seriesuid, 'minX': minX, 'minY': minY, 'coordZ': coordZ,\n",
    "# 'width': width, 'height': height, 'diameterZ':diameterZ,\n",
    "# 'label': label, 'probability': probability})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# from get_image_and_label import get_image_and_label\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/external-libraries')\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import paddlex as pdx\n",
    "import json\n",
    "os.chdir('/home/aistudio/work')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "# matplotlib.use('Agg') \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#图像增强\n",
    "from paddlex.cls import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Normalize()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    MIN_BOUND = np.min(image)\n",
    "    MAX_BOUND = np.max(image)\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image > 1] = 1.\n",
    "    image[image < 0] = 0.\n",
    "    return image\n",
    "\n",
    "def get_file_id(file_path):\n",
    "    files = []\n",
    "    for f_name in [f for f in os.listdir(file_path) if f.endswith('.mhd')]:\n",
    "        f_name = f_name.replace('.mhd', '')\n",
    "        files.append(f_name)\n",
    "    return sorted(files)\n",
    "\n",
    "\n",
    "def load_itk(file):\n",
    "    itkimage = sitk.ReadImage(file)\n",
    "    ct_scan = sitk.GetArrayFromImage(itkimage)\n",
    "    origin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    return ct_scan, origin, spacing\n",
    "\n",
    "\n",
    "# def DoResnetPredict():\n",
    "# model = load_model('./saved_models/trained_weights_final_ResNet.h5')\n",
    "model = pdx.load_model('resnet_output/resnet_50/best_model')\n",
    "# model.summary()\n",
    "predict_path = './predict_result/train_predict_frcnn_cut_testA.csv'\n",
    "data_path = '/home/aistudio/data/data8689/testA'\n",
    "predict_anns_all = pd.read_csv(predict_path)\n",
    "target_size = 64\n",
    "save_name = './predict_result/test_file_final_predict_frcnn_testA_ResNet1.csv'\n",
    "# seriesuid, coordX, coordY, coordZ, class_label, probability = [], [], [], [], [], []\n",
    "seriesuid, minX, minY, coordZ, width, height, label, probability = [], [], [], [], [], [], [], []\n",
    "trueProb = []\n",
    "file_ids = get_file_id(data_path)\n",
    "for current_id in tqdm(file_ids):\n",
    "    current_file = os.path.join(data_path, current_id + '.mhd')\n",
    "    ct, origin, spacing = load_itk(current_file)\n",
    "    predict_ann_df = predict_anns_all.query('seriesuid == \"%s\"' % current_id).copy()\n",
    "\n",
    "    # for _, predict_ann in tqdm(predict_ann_df.iterrows()):\n",
    "    for _, predict_ann in predict_ann_df.iterrows():\n",
    "        # pre_x, pre_y, pre_z, pre_w, pre_h = predict_ann.coordX, predict_ann.coordY, predict_ann.coordZ, predict_ann.diameterX, predict_ann.diameterY\n",
    "        pre_minX, pre_minY, pre_z, pre_w, pre_h = predict_ann.minX, predict_ann.minY, predict_ann.coordZ, predict_ann.width, predict_ann.height\n",
    "        #计算中心节点坐标\n",
    "        # pre_x = pre_minX + pre_w * 0.5\n",
    "        # pre_y = pre_minY + pre_h * 0.5\n",
    "        current_image = ct[int(pre_z)]\n",
    "\n",
    "        w, h = int(pre_w), int(pre_h)\n",
    "        # pre_x_min, pre_x_max = int(pre_x - pre_w / 2), int(pre_x + pre_w / 2)\n",
    "        # pre_y_min, pre_y_max = int(pre_y - pre_h / 2), int(pre_y + pre_h / 2)\n",
    "        pre_x_min = int(pre_minX)\n",
    "        pre_x_max = int(pre_minX) + int(pre_w)\n",
    "        pre_y_min = int(pre_minY)\n",
    "        pre_y_max = int(pre_minY) + int(pre_h)\n",
    "\n",
    "        if w > target_size or h > target_size:\n",
    "            max_size = int(max(w, h))\n",
    "            result_image = np.zeros((max_size, max_size))\n",
    "            result_image[0:int(h), 0:int(w)] = current_image[pre_y_min:pre_y_max, pre_x_min:pre_x_max]\n",
    "            result_image = cv2.resize(result_image, (target_size, target_size))\n",
    "        else:\n",
    "            result_image = current_image[pre_y_min:pre_y_max, pre_x_min:pre_x_max]\n",
    "            result_image = cv2.copyMakeBorder(result_image,\n",
    "                                                int((target_size - h) / 2), math.ceil((target_size - h) / 2),\n",
    "                                                int((target_size - w) / 2), math.ceil((target_size - w) / 2),\n",
    "                                                cv2.BORDER_CONSTANT, value=0)\n",
    "        # result_image = normalize(result_image)\n",
    "        cv2.imwrite('./tempPredictResNetImg.png', result_image)\n",
    "        temp_image = './tempPredictResNetImg.png'\n",
    "        predict_image = model.predict(temp_image,transforms=eval_transforms)\n",
    "        os.remove('./tempPredictResNetImg.png')\n",
    "        if predict_image[0]['category_id'] ==0:\n",
    "            if predict_ann.probability >=0.7 and predict_image[0]['score']<= 0.9:\n",
    "                seriesuid.append(int(current_id))\n",
    "                minX.append(predict_ann.minX)\n",
    "                minY.append(predict_ann.minY)\n",
    "                coordZ.append(int(pre_z))\n",
    "                width.append(predict_ann.width) \n",
    "                height.append(predict_ann.height)\n",
    "                label.append(predict_ann.label)\n",
    "                trueProb.append(predict_image[0])\n",
    "                probability.append(predict_ann.probability)\n",
    "        else:\n",
    "            if predict_ann.probability >=0.7 and predict_image[0]['score'] >= 0.9:\n",
    "                seriesuid.append(int(current_id))\n",
    "                minX.append(predict_ann.minX)\n",
    "                minY.append(predict_ann.minY)\n",
    "                coordZ.append(int(pre_z))\n",
    "                width.append(predict_ann.width) \n",
    "                height.append(predict_ann.height)\n",
    "                label.append(predict_ann.label)\n",
    "                trueProb.append(predict_image[0])\n",
    "                probability.append(predict_ann.probability)\n",
    "    \n",
    "dataframe = pd.DataFrame({'seriesuid': seriesuid, 'minX': minX, 'minY': minY, 'coordZ': coordZ,\n",
    "                        'width': width, 'height': height,'label': label, 'probability': probability})\n",
    "columns = ['seriesuid', 'minX', 'minY', 'coordZ', 'width', 'height', 'label', 'probability']\n",
    "dataframe.to_csv(save_name, index=False, sep=',', columns=columns)\n",
    "dataframe['trueType'] = list(map(lambda x:x.get('category'),trueProb))\n",
    "dataframe['trueProb'] = list(map(lambda x:float(x.get('score')),trueProb))\n",
    "dataframe.to_csv(save_name, index=False, sep=',', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe['trueType'] = list(map(lambda x:x.get('category'),trueProb))\n",
    "dataframe['trueProb'] = list(map(lambda x:float(x.get('score')),trueProb))\n",
    "dataframe.to_csv(save_name, index=False, sep=',', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "#对训练数据进行批量预测\n",
    "import pandas as pd\n",
    "import paddlex as pdx\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from paddlex.det import transforms\n",
    "\n",
    "def load_itk(file):\n",
    "    itkimage = sitk.ReadImage(file)\n",
    "    ct_scan = sitk.GetArrayFromImage(itkimage)\n",
    "    origin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "\n",
    "    return ct_scan, origin, spacing\n",
    "\n",
    "\n",
    "def frcnn_predict(fileName,output_path = './predict_result/',clipmin=-1000, clipmax=600):\n",
    "    # os.chdir('/home/aistudio/work')\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    #加载模型\n",
    "    #对训练数据fcrnn预测\n",
    "    model = pdx.load_model('output/faster_rcnn_r50_fpn/epoch_12')\n",
    "\n",
    "    eval_transforms = transforms.Compose([\n",
    "        transforms.Normalize()\n",
    "    ])\n",
    "\n",
    "    save_name = 'temp_frcnn_predict_result.txt'\n",
    "    origin_save_name = 'origin_predict_result.txt'\n",
    "    origin_predict_result = []\n",
    "    # file_path = './predict_result'\n",
    "    seriesuid, minX, minY, coordZ, width, height, diameterZ, label, probability = [], [], [], [], [], [], [], [], []\n",
    "    f_name = fileName\n",
    "    result_id = f_name.replace('.mhd', '')\n",
    "    # current_file = os.path.join(file_path, f_name)\n",
    "    current_file = f_name\n",
    "    ct, origin, spacing = load_itk(current_file)\n",
    "    ct = ct.clip(min=clipmin, max=clipmax)\n",
    "    for num in tqdm(range(ct.shape[0])):\n",
    "        # image = pre_predict_image_process(Image.fromarray(ct[num]))\n",
    "        # image  = np.expand_dims(ct[num], 0)\n",
    "        cv2.imwrite('./tempPredictImg.png', ct[num])\n",
    "        image = './tempPredictImg.png'\n",
    "        detect_result = model.predict(image,transforms=eval_transforms)\n",
    "        os.remove('./tempPredictImg.png')\n",
    "        # print(detect_result)\n",
    "        for one_result in detect_result:\n",
    "            result_probability = one_result['score']\n",
    "            result_label = one_result['category']\n",
    "            seriesuid.append(result_id)\n",
    "            label.append(result_label)\n",
    "            probability.append(result_probability)\n",
    "            minX.append(one_result['bbox'][0])\n",
    "            minY.append(one_result['bbox'][1])\n",
    "            coordZ.append(num)\n",
    "            width.append(one_result['bbox'][2])\n",
    "            height.append(one_result['bbox'][3])\n",
    "            diameterZ.append(1)\n",
    "            #按照原始格式存储图像预测结果\n",
    "            origin_predict_result.append({'diameterZ':num,'predict_result':one_result})\n",
    "    dataframe = pd.DataFrame({'seriesuid': seriesuid, 'minX': minX, 'minY': minY, 'coordZ': coordZ,\n",
    "                                'width': width, 'height': height, 'diameterZ':diameterZ,\n",
    "                                'label': label, 'probability': probability})\n",
    "    columns = ['seriesuid', 'minX', 'minY', 'coordZ', 'width', 'height', 'diameterZ', 'label', 'probability']\n",
    "    dataframe.to_csv(output_path+save_name, index=False, sep=',', columns=columns)\n",
    "\n",
    "    testFCRNNPredictResultDF = pd.DataFrame(origin_predict_result)\n",
    "    testFCRNNPredictResultDF.to_csv(output_path+origin_save_name)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-29 19:13:40 [INFO]\tModel[FasterRCNN] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/295 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imgaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-cb86d2dcc825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aistudio/work'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfrcnn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aistudio/data/data8689/testA/340518.mhd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ffb27b479dc3>\u001b[0m in \u001b[0;36mfrcnn_predict\u001b[0;34m(fileName, output_path, clipmin, clipmax)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tempPredictImg.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./tempPredictImg.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mdetect_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tempPredictImg.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# print(detect_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/faster_rcnn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, img_file, transforms)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         im, im_resize_info, im_shape = FasterRCNN._preprocess(\n\u001b[0;32m--> 431\u001b[0;31m             images, transforms, self.model_type, self.__class__.__name__)\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/faster_rcnn.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(images, transforms, model_type, class_name, thread_num)\u001b[0m\n\u001b[1;32m    384\u001b[0m             mode='test')\n\u001b[1;32m    385\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/transforms/cls_transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, im, label)\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAugmenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_imgaug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imgaug'"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/aistudio/work')\n",
    "frcnn_predict('/home/aistudio/data/data8689/testA/340518.mhd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  diameterZ                                     predict_result\n",
      "0           0          0  {'category_id': 2, 'bbox': [388.2894592285156,...\n",
      "0    {'category_id': 2, 'bbox': [388.2894592285156,...\n",
      "Name: predict_result, dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "origin_resnetDF = pd.read_csv('./predict_result/origin_predict_result.txt')\n",
    "# print(origin_resnetDF)\n",
    "predict_ann_df = origin_resnetDF.query('diameterZ == \"%s\"' % 0).copy()\n",
    "print(predict_ann_df)\n",
    "print(predict_ann_df['predict_result'])\n",
    "print(predict_ann_df['diameterZ'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex.cls import transforms\n",
    "def resnet_predict(fileName,temp_rcnn_predict_file,origin_predict_file,\n",
    "                    output_path = './predict_result/',\n",
    "                    clipmin=-1000, clipmax=600):\n",
    "    #对结果进行假阳性预判\n",
    "    #加载resnet 模型\n",
    "    model1 = pdx.load_model('resnet_output/resnet_50/best_model')\n",
    "    # model.summary()\n",
    "    predict_path = temp_rcnn_predict_file\n",
    "    predict_anns_all = pd.read_csv(output_path+predict_path)\n",
    "    target_size = 64\n",
    "    final_save_name = output_path + 'final_predict_frcnn_ResNet.txt'\n",
    "    origin_final_save_name = output_path + 'final_origin_frcnn_ResNet.txt'\n",
    "\n",
    "    seriesuid, minX, minY, coordZ, width, height, label, probability = [], [], [], [], [], [], [], []\n",
    "    trueProb = []\n",
    "    origin_resnet_result_for_draw = []\n",
    "    origin_resnetDF = pd.read_csv(output_path+origin_predict_file)\n",
    "\n",
    "    eval_transforms = transforms.Compose([\n",
    "        transforms.Normalize()\n",
    "    ])\n",
    "\n",
    "    file_ids = fileName.replace('.mhd', '')\n",
    "    # current_file = os.path.join(data_path, current_id + '.mhd')\n",
    "    current_file = fileName\n",
    "    current_id = file_ids\n",
    "    ct, origin, spacing = load_itk(current_file)\n",
    "    # ct = ct.clip(min=clipmin, max=clipmax)\n",
    "    predict_ann_df = predict_anns_all.query('seriesuid == \"%s\"' % current_id).copy()\n",
    "\n",
    "    for _, predict_ann in tqdm(predict_ann_df.iterrows()):\n",
    "    # for _,predict_ann in tqdm(predict_ann_df):\n",
    "        pre_minX, pre_minY, pre_z, pre_w, pre_h = predict_ann.minX, predict_ann.minY, predict_ann.coordZ, predict_ann.width, predict_ann.height\n",
    "        #计算中心节点坐标\n",
    "        current_image = ct[int(pre_z)]\n",
    "\n",
    "        w, h = int(pre_w), int(pre_h)\n",
    "        pre_x_min = int(pre_minX)\n",
    "        pre_x_max = int(pre_minX) + int(pre_w)\n",
    "        pre_y_min = int(pre_minY)\n",
    "        pre_y_max = int(pre_minY) + int(pre_h)\n",
    "\n",
    "        if w > target_size or h > target_size:\n",
    "            max_size = int(max(w, h))\n",
    "            result_image = np.zeros((max_size, max_size))\n",
    "            result_image[0:int(h), 0:int(w)] = current_image[pre_y_min:pre_y_max, pre_x_min:pre_x_max]\n",
    "            result_image = cv2.resize(result_image, (target_size, target_size))\n",
    "        else:\n",
    "            result_image = current_image[pre_y_min:pre_y_max, pre_x_min:pre_x_max]\n",
    "            result_image = cv2.copyMakeBorder(result_image,\n",
    "                                                int((target_size - h) / 2), math.ceil((target_size - h) / 2),\n",
    "                                                int((target_size - w) / 2), math.ceil((target_size - w) / 2),\n",
    "                                                cv2.BORDER_CONSTANT, value=0)\n",
    "        cv2.imwrite('./tempPredictResNetImg.png', result_image)\n",
    "        temp_image = './tempPredictResNetImg.png'\n",
    "        predict_image = model1.predict(temp_image,transforms=eval_transforms)\n",
    "        # print(predict_image)\n",
    "        os.remove('./tempPredictResNetImg.png')\n",
    "        if predict_image[0]['category_id'] ==0:\n",
    "            #如果frcnn预测结果大于0.7 并且假阳性False概率小于90% 则认为最终结果\n",
    "            if predict_ann.probability >=0.7 and predict_image[0]['score']<= 0.9:\n",
    "                print('yes')\n",
    "                seriesuid.append(int(current_id))\n",
    "                minX.append(predict_ann.minX)\n",
    "                minY.append(predict_ann.minY)\n",
    "                coordZ.append(int(pre_z))\n",
    "                width.append(predict_ann.width) \n",
    "                height.append(predict_ann.height)\n",
    "                label.append(predict_ann.label)\n",
    "                trueProb.append(predict_image[0])\n",
    "                probability.append(predict_ann.probability)\n",
    "                #将原始的预测格式存储，以便画图\n",
    "                origin_predict_result_temp = origin_resnetDF.query('diameterZ == \"%s\"' % int(pre_z)).copy()\n",
    "                # print(predict_ann_df)\n",
    "                # print(predict_ann_df['predict_result'])\n",
    "                origin_resnet_result_for_draw.append(origin_predict_result_temp)\n",
    "\n",
    "        else:\n",
    "            #如果frcnn预测结果大于0.7 并且假阳性True概率大于90% 则认为最终结果\n",
    "            if predict_ann.probability >=0.7 and predict_image[0]['score'] >= 0.9:\n",
    "                seriesuid.append(int(current_id))\n",
    "                minX.append(predict_ann.minX)\n",
    "                minY.append(predict_ann.minY)\n",
    "                coordZ.append(int(pre_z))\n",
    "                width.append(predict_ann.width) \n",
    "                height.append(predict_ann.height)\n",
    "                label.append(predict_ann.label)\n",
    "                trueProb.append(predict_image[0])\n",
    "                probability.append(predict_ann.probability)\n",
    "                #将原始的预测格式存储，以便画图\n",
    "                origin_predict_result_temp = origin_resnetDF.query('diameterZ == \"%s\"' % int(pre_z)).copy()\n",
    "                # print(predict_ann_df)\n",
    "                # print(predict_ann_df['predict_result'])\n",
    "                origin_resnet_result_for_draw.append(origin_predict_result_temp)\n",
    "\n",
    "\n",
    "    dataframe = pd.DataFrame({'seriesuid': seriesuid, 'minX': minX, 'minY': minY, 'coordZ': coordZ,\n",
    "                        'width': width, 'height': height,'label': label, 'probability': probability})\n",
    "    columns = ['seriesuid', 'minX', 'minY', 'coordZ', 'width', 'height', 'label', 'probability']\n",
    "    dataframe.to_csv(final_save_name, index=False, sep=',', columns=columns)\n",
    "    dataframe['trueType'] = list(map(lambda x:x.get('category'),trueProb))\n",
    "    dataframe['trueProb'] = list(map(lambda x:float(x.get('score')),trueProb))\n",
    "    dataframe.to_csv(final_save_name, index=False, sep=',', columns=columns)\n",
    "\n",
    "    #存储最终的画图结果\n",
    "    testFCRNNPredictResultDF = pd.DataFrame(origin_resnet_result_for_draw)\n",
    "    testFCRNNPredictResultDF.to_csv(origin_final_save_name)\n",
    "    #画图\n",
    "    for i in range(origin_resnet_result_for_draw.__len__()):\n",
    "        # origin_resnet_result_for_draw\n",
    "        tempPredictPNGName = output_path+'tempPNG'+str(i)+'.png'\n",
    "        cv2.imwrite(tempPredictPNGName, ct[int(origin_resnet_result_for_draw['diameterZ'][0])])\n",
    "        # os.remove('./tempPredictImg.png')\n",
    "        pdx.det.visualize(tempPredictPNGName, origin_resnet_result_for_draw[i], threshold=0.5,save_dir=output_path)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "save_name = 'temp_frcnn_predict_result.txt'\n",
    "origin_save_name = 'origin_predict_result.txt'\n",
    "resnet_predict('/home/aistudio/data/data8689/testA/689194.mhd',save_name,origin_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-29 19:20:35 [INFO]\tModel[FasterRCNN] loaded.\n",
      "2020-08-29 19:20:36 [INFO]\tModel[ResNet50] loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/295 [00:20<10:52,  2.28s/it]"
     ]
    }
   ],
   "source": [
    "from work.LungCT2019 import predict_final_frcnn_resnet\n",
    "import os\n",
    "os.chdir('/home/aistudio/work')\n",
    "predict_final_frcnn_resnet.frcnn_predict('/home/aistudio/data/data8689/testA/340518.mhd')\n",
    "save_name = 'temp_frcnn_predict_result.txt'\n",
    "origin_save_name = 'origin_predict_result.txt'\n",
    "predict_final_frcnn_resnet.resnet_predict('/home/aistudio/data/data8689/testA/340518.mhd',save_name,origin_save_name)\n",
    "predict_final_frcnn_resnet.drawPredictPic('/home/aistudio/data/data8689/testA/340518.mhd','final_origin_frcnn_ResNet.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
